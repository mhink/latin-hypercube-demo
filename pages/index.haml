- var pdf_x = "&phi;<sub>x</sub>"
- var pdf_y = "&phi;<sub>y</sub>"
- var cdf_x = "&phi;<sub>x</sub>"
- var cdf_y = "&phi;<sub>y</sub>"
- var unif  = "&#119984;"
- var rv_B  = "&#119809;"
- var fsub_B = "&#119891;<sub>"+rv_B+"</sub>";
- var norm  = "&#119977;"
- var reals = "&#119825;"
!!! 5
%html
  %head
    %title Turning Bytes into Bell Curves
    %link(rel="stylesheet" href="assets/global.css")
    %script(src="assets/global.js")
  %body
    .page-container
      %header
        %h1 Turning Bytes into Bell Curves
        %h3 Random Sampling: An Interactive Demo
      %section#intro
        %p Of all my university classes, my favorites were the ones dealing with probability. Sure, other subjects turned out to be useful- but when, for instance, <a href="http://setosa.io/conditional/" target="_blank">Bayes' Theorem</a> finally clicked, it felt like <em>magic</em>.
        %p To my surprise, though, more than a few of my more traditional CS friends seem a bit mystified by the topic. Ask them to about custom memory managers, complicated graphics routines, or database query optimization and they'll go on for days- but if you bring up Monte Carlo methods, they glaze over and start thinking about James Bond playing baccarat!
        %p So for their sake, we're going to look at a basic topic that sits close to the intersection of computer science and statistics: drawing random samples from a normal distribution. There are several ways to do this, but we'll focus on three: inverse transform sampling, the Box-Mueller Transform, and the Ziggurat algorithm.

      %section#sampling-bytes
        %h3 Sampling Bytes
        %p If we want to sample random numbers, we need a source of randomness. Thanks to the <a href="https://developer.mozilla.org/en-US/docs/Web/API/RandomSource/getRandomValues" target="_blank">Web Cryptography API</a>, I just so happen to have a stream of random bytes right here:
        #random-byte-samples

        %p Mathematically, the result of taking one sample of this stream is a random variable <span>!{rv_B} = !{unif}{0, 255}</span>.  Accordingly, the probability of any particular outcome is <span>!{fsub_B} (b) = 1/256</span>, or about <em>0.0039</em>.
        %p In order to get a better idea of what this means, the bar graph below shows all possible outcomes, with their relative rates of occurrence.  If our distribution of bytes is truly uniform, these bars should settle at 0.39%.

        #uniform-sample-rates PLACEHOLDER

      %section#continuity
        %h3 Continuity
        %p Many useful distributions, including the normal, are continuous- that is to say, they have a . but we obviously can't represent the entirety of !{reals} on a <em>digital</em> computer- we're going to have to settle for an approximation.  If we convert our values to a distribution over the interval [0, 1), we'll be able to translate and scale
        #random-float-samples 
      -# %section#two-distributions
      -#   %p Say we have two probability distributions !{pdf_x}, !{pdf_y}.
